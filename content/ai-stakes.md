---
title: AI's Quest for Bias-Free Enlightenment
date: 2024-02-23
---

This week, Google's newly released Gemini product demonstrated some notable inaccuracies. When generating images of historical figures like George Washington, Gemini [sometimes depicted them with incorrect races or genders](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical).

<img src="/images/wash.png" alt="Manifest Destiny" style="width:50%;height: auto;">

Asked why it altered Washington's race, Gemini explained that it "aimed to provide a more accurate and inclusive representation..."  Perhaps, like the movie Inglorious Basterds, an alternate timeline in which Washington is black might be for the best.

Whether you prefer a black, asian, or white George Washington, Gemini's behavior is a reminder that AI is shaped solely by its training data and reflects the biases of the engineers who curate that data. Google chose training data influenced by their biases.

**Engineering Human Values**

Google has temporarily disabled image generation for prompts like this. So today - when I asked Gemini to generate an image depicting "Manifest Destiny" it opted for a Wikipedia image instead. But let's pretend for a moment that Gemini generated the image, or something like it. Here it is.

<img src="/images/American_Progress_(John_Gast_painting).jpg" alt="Manifest Destiny" style="width:50%;height: auto;">

The picture shows Columbia, a positive personification of America, leading the way West. Native Americans don't really play a big role in the image. If you look carefully you can see some figures fading into the darkness, but they're easy to miss. It's easy to understand how people might find this kind of imagery troubling. It glosses over a dark and painful history. Whether Gemini chooses this history, or some other one, is up to a small team and their values.

**Reflecting Fears through AI's Lens**

Not only is this a huge challenge for companies like Google, OpenAI, and Meta, but it's also genuinely terrifying for society. Imagine a right-wing version of Gemini trained on data from the growing [National Conservatism movement](https://www.theatlantic.com/ideas/archive/2021/11/scary-future-american-right-national-conservatism-conference/620746/). What would Gemini generate in response to a prompt about "immigration?" 

Tech giants like Google, OpenAI, and Meta will never be able to create a generally acceptable form of AI-generated "truth." Of course, that's impossible. But that won't stop them from trying. Perhaps users will have settings to tailor the political bias of the answers they receive, ensuring they reflect their own worldviews.  More likely, we'll see a proliferation of AI engines targeted at specific audiences, furthering the divide we already see in the media.