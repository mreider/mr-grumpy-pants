---
title: AI's Quest for Bias-Free Enlightenment
date: 2024-02-23
---

This week, Google's Gemini engine demonstrated how AI is destined for biases and blind spots. When asked to generate images of historical figures, [Gemini consistently failed to produce accurate results](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical), depicting them as the wrong races or genders.

It's a reminder that the development of AI is profoundly shaped by its training data, reflecting the biases and perspectives of the engineers at companies like Google or OpenAI who curate it. Their selections, influenced by their own inherent biases and blind spots, change how these products perform and interact with users.

**Engineering Human Values**

AI companies now face an impossible challenge: embedding universal values into ChatGPT and Gemini without stepping on cultural landmines. Perhaps they'll lean towards "customizable outputs." A sensitivity-slider. Something that allows users to tweak things to fit their worldview. Of course that won't end well either.

The question then becomes: Will tech giants commit to specific values in their AI offerings, or will they drive to appease a broad ideological audience instead?

**Ancient BIOS vs. Modern GPUs**

It's pretty ironic: we're channeling massive resources into advanced GPUs for AI, yet our collective BIOS remains in the Stone Age. Trying to curate training data that pleases everyone is like attempting to craft a universal religion. Utterly impossible.
