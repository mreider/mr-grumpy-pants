---
title: AI's Quest for Bias-Free Enlightenment
date: 2024-02-23
---

This week, Google Gemini demonstrated how AI is destined for biases and blind spots. When asked to generate images of historical figures, [Gemini consistently failed to produce accurate results](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical), depicting the Founding Fathers as the wrong race and gender.

It's a reminder that AI is shaped only by its training data, and reflects the biases and perspectives of the engineers who curate that data. Their selections, influenced by their own inherent biases and blind spots, change how these products behave.

**Engineering Human Values**

AI teams at Google, OpenAI, and Meta face an impossible challenge. How do you embed universal values into ChatGPT and Gemini without stepping on cultural landmines? 

Maybe the answer lies in customizable outputs. Something like a sensitivity-slider - where users can tweak responses to fit their worldviews. No. That won't end well either.

**Ancient BIOS vs. Modern GPUs**

It's pretty ironic: we're channeling massive resources into advanced GPUs for AI, yet our collective BIOS remains in the Stone Age. Trying to curate training data that pleases everyone is like attempting to craft a universal religion. Utterly impossible.
